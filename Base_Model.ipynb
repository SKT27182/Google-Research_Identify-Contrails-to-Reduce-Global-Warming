{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:04:51.883967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\"):\n",
    "    BASE_DIR = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n",
    "else:\n",
    "    BASE_DIR =  'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = Namespace(\n",
    "        base_dir= BASE_DIR,\n",
    "        batch_size= 32,\n",
    "        learning_rate= 0.001,\n",
    "        epochs= 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_idx = pd.DataFrame({'idx': os.listdir(f'{configs.base_dir}/train')})\n",
    "df_validation_idx = pd.DataFrame({'idx': os.listdir(f'{configs.base_dir}/validation')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_T11_BOUNDS = (243, 303)\n",
    "_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "_TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "\n",
    "def get_band_images(idx, parent_folder, band):\n",
    "    return np.load(os.path.join(configs.base_dir, parent_folder, idx, f'band_{band}.npy'))\n",
    "\n",
    "\n",
    "def normalize_range(data, bounds):\n",
    "    \"\"\"Maps data to the range [0, 1].\"\"\"\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "\n",
    "def get_ash_color_images(idx, parent_folder, get_mask_frame_only=False):\n",
    "    band11 = get_band_images(idx, parent_folder, '11')\n",
    "    band14 = get_band_images(idx, parent_folder, '14')\n",
    "    band15 = get_band_images(idx, parent_folder, '15')\n",
    "    \n",
    "    if get_mask_frame_only:\n",
    "        band11 = band11[:,:,4]\n",
    "        band14 = band14[:,:,4]\n",
    "        band15 = band15[:,:,4]\n",
    "\n",
    "    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n",
    "    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    b = normalize_range(band14, _T11_BOUNDS)\n",
    "    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "    return false_color\n",
    "\n",
    "def get_mask_image(idx, parent_folder):\n",
    "    return np.load(os.path.join(configs.base_dir, parent_folder, idx, 'human_pixel_masks.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrailsAshDataset():\n",
    "    def __init__(self, parent_folder):\n",
    "        self.df_idx = pd.DataFrame({'idx': os.listdir(f'{configs.base_dir}/{parent_folder}')})\n",
    "        self.parent_folder = parent_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = str(self.df_idx.iloc[idx]['idx'])\n",
    "        images = np.reshape(get_ash_color_images(image_id, self.parent_folder, get_mask_frame_only=False), (256, 256, 24)).astype(np.float32)\n",
    "        mask = get_mask_image(image_id, self.parent_folder).astype(np.float32)\n",
    "      \n",
    "        return images, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "class GetDataloader():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "    def dataloader(self, dataset, data_type='train'):\n",
    "        # Create dataset from the ContrailsAshDataset object\n",
    "        dataloader = tf.data.Dataset.from_generator(\n",
    "            lambda: dataset,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(256, 256, 24), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Shuffle if it's for training\n",
    "        if data_type == 'train':\n",
    "            dataloader = dataloader.shuffle(self.args.batch_size)\n",
    "\n",
    "        # Add general transformations\n",
    "        dataloader = (\n",
    "            dataloader\n",
    "            .batch(self.args.batch_size)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        )\n",
    "\n",
    "        return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 24), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = ContrailsAshDataset('train')\n",
    "\n",
    "train_dataloader = GetDataloader(configs).dataloader(dataset_train, data_type=\"train\")\n",
    "\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 256, 256, 24)\n",
      "(6, 256, 256, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:05:02.854893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-14 11:05:02.855226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# print shape of one batch\n",
    "for images, masks in train_dataloader.take(1):\n",
    "    print(images.shape)\n",
    "    print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 24), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val = ContrailsAshDataset('validation')\n",
    "\n",
    "val_dataloader = GetDataloader(configs).dataloader(dataset_val, data_type=\"val\")\n",
    "\n",
    "val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 2  0           []                               \n",
      "                                4)]                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  13888       ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['max_pooling2d[0][0]']          \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['batch_normalization[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16, 16, 512)  0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  4719104    ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 512)  0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  1179904    ['dropout_2[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  295040     ['conv2d_13[0][0]']              \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128, 128, 12  0           ['conv2d_15[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  73792      ['dropout_3[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,525,697\n",
      "Trainable params: 34,525,569\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define U-Net model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def iou_coef_loss(y_true, y_pred):\n",
    "    return 1 - iou_coef(y_true, y_pred)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "class UNet:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def _conv_block(self, input_tensor, n_filters, kernel_size=3):\n",
    "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding=\"same\")(input_tensor)\n",
    "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding=\"same\")(x)\n",
    "        return x\n",
    "\n",
    "    def resnet_encoder(self, input_tensor, filters):\n",
    "        skip= self._conv_block(input_tensor, filters)\n",
    "        x = MaxPooling2D((2, 2))(skip)\n",
    "\n",
    "        return x, skip\n",
    "    \n",
    "    def resnet_decoder(self, input_tensor, skip_tensor, filters):\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(input_tensor)\n",
    "        x = concatenate([x, skip_tensor])\n",
    "        x = self._conv_block(x, filters)\n",
    "        return x\n",
    "    \n",
    "    def bottleneck(self, input_tensor, filters):\n",
    "        x = self._conv_block(input_tensor, filters)\n",
    "        return x\n",
    "\n",
    "    def build(self):\n",
    "\n",
    "        input_tensor = Input(shape=self.input_shape)\n",
    "        x = input_tensor\n",
    "\n",
    "        \n",
    "\n",
    "        # Encoder\n",
    "        x, skip1 = self.resnet_encoder(x, 64)\n",
    "        # Add batch normalization layer\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x, skip2 = self.resnet_encoder(x, 128)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x, skip3 = self.resnet_encoder(x, 256)\n",
    "        x, skip4 = self.resnet_encoder(x, 512)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x, 1024)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.resnet_decoder(x, skip4, 512)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = self.resnet_decoder(x, skip3, 256)\n",
    "        x = self.resnet_decoder(x, skip2, 128)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = self.resnet_decoder(x, skip1, 64)\n",
    "\n",
    "        # Output\n",
    "        output_tensor = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(input_tensor, output_tensor)\n",
    "        return model\n",
    "\n",
    "    # add dice_coef to loss\n",
    "    # def compile(self, optimizer, loss, metrics):\n",
    "    #     super().compile(\n",
    "    #         optimizer=optimizer\n",
    "    #     )\n",
    "\n",
    "# create model\n",
    "\n",
    "model = UNet((256, 256, 24)).build()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=iou_coef_loss,\n",
    "    metrics=[iou_coef, dice_coef]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:05:15.187600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-14 11:05:15.187848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-14 11:05:18.465037: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 100663296 exceeds 10% of free system memory.\n",
      "2023-07-14 11:05:18.545534: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 100663296 exceeds 10% of free system memory.\n",
      "2023-07-14 11:05:19.958309: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 100663296 exceeds 10% of free system memory.\n",
      "2023-07-14 11:05:20.307043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 100663296 exceeds 10% of free system memory.\n",
      "2023-07-14 11:05:20.465973: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 201326592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 18s 18s/step - loss: 0.9888 - iou_coef: 0.0112 - dice_coef: 0.0215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:05:33.845380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 21s 21s/step - loss: 0.9888 - iou_coef: 0.0112 - dice_coef: 0.0215 - val_loss: 1.0000 - val_iou_coef: 2.5391e-05 - val_dice_coef: 2.5391e-05\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.9867 - iou_coef: 0.0133 - dice_coef: 0.0253 - val_loss: 1.0000 - val_iou_coef: 1.8966e-05 - val_dice_coef: 1.8966e-05\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.9862 - iou_coef: 0.0138 - dice_coef: 0.0262 - val_loss: 0.9999 - val_iou_coef: 6.5883e-05 - val_dice_coef: 6.5883e-05\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.9854 - iou_coef: 0.0146 - dice_coef: 0.0270 - val_loss: 0.9990 - val_iou_coef: 9.7950e-04 - val_dice_coef: 9.7950e-04\n"
     ]
    }
   ],
   "source": [
    "# model = UNet((256, 256, 24)).build()\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# # train model\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=configs.learning_rate), loss=iou_coef_loss, metrics=[iou_coef, dice_coef])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1, restore_best_weights=True, monitor='loss'),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "# history = model.fit(train_dataloader, epochs=configs.epochs, callbacks=callbacks, verbose=1)\n",
    "\n",
    "history = model.fit(train_dataloader, epochs=4, verbose=1, validation_data=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_idx = pd.DataFrame({'idx': os.listdir(f'{configs.base_dir}/test')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"test\"\n",
    "\n",
    "# get test images in the form of batch\n",
    "def get_test_images(test_dir):\n",
    "    test_images = []\n",
    "    for idx in os.listdir(os.path.join(configs.base_dir, test_dir)):\n",
    "        # image_path = os.path.join(test_dir, idx)\n",
    "        image = get_ash_color_images(idx, test_dir, get_mask_frame_only=False)\n",
    "        test_images.append(image)\n",
    "    test_images = np.array(test_images)\n",
    "    return np.reshape(test_images, (len(test_images), 256, 256, 24))\n",
    "\n",
    "\n",
    "test_images = get_test_images(\"test\")\n",
    "\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image, threshold):\n",
    "    mask = tf.math.greater(image, threshold)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "masked_pred = create_mask(predictions, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rle encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source https://www.kaggle.com/code/inversion/contrails-rle-submission?scriptVersionId=128527711&cellId=4\n",
    "\n",
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns: run length encoding as list\n",
    "    \"\"\"\n",
    "\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    Converts list to a string representation\n",
    "    Empty list returns '-'\n",
    "    \"\"\"\n",
    "    if x: # non-empty list\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s\n",
    "\n",
    "len(list_to_string(rle_encode(np.array(masked_pred)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_pixels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000834164244036115</th>\n",
       "      <td>17 73 101 1 103 1 105 1 107 1 109 37 270 78 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002653297254493116</th>\n",
       "      <td>1 25 51 37 98 8 145 137 306 38 353 10 400 139 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        encoded_pixels\n",
       "record_id                                                             \n",
       "1000834164244036115  17 73 101 1 103 1 105 1 107 1 109 37 270 78 35...\n",
       "1002653297254493116  1 25 51 37 98 8 145 137 306 38 353 10 400 139 ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a submission dataframe with record_id as index and rle string as column\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['encoded_pixels'])\n",
    "submission_df.index.name = 'record_id'\n",
    "\n",
    "for i in range(len(masked_pred)):\n",
    "    submission_df.loc[df_test_idx.iloc[i][\"idx\"], 'encoded_pixels'] = list_to_string(rle_encode(np.array(masked_pred)[i]))\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
